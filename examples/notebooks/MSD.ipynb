{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4\n",
    "\n",
    "## Mean Squared Displacement (MSD)\n",
    "\n",
    "\n",
    "Molecules in liquds, gases and solids do not stay in the same place and move constantly. Think about a drop of dye in a glass of water, as time passes the dye distributes throughout the water. This process is called diffusion and is common throughout nature and an incredibly relevant property for materials scientists who work on things like batteries.  \n",
    "\n",
    "Using the dye as an example, the motion of a dye molecule is not simple. As it moves it is jostled by collisions with other molecules, preventing it from moving in a straight path. If the path is examined in close detail, it will be seen to be a good approximation to a random walk. In mathmatics a random walk is a series of steps, each taken in a random direction. This was analysed by Albert Einstein in a study of Brownian motion and he showed that the mean square of the distance travelled by a particle following a random walk is proportional to the time elapsed. \n",
    "\n",
    "\\begin{align}\n",
    "\\Big \\langle r_{i}^{2} \\big \\rangle & = 6 D_t + C \n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "\\begin{align}\n",
    "\\Big \\langle r_{i}^{2} \\big \\rangle = \\frac{1}{3} \\Big< | r_{i}(t) - r_{i}(0) |^2 \\Big>.\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "where $\\Big \\langle r^2 \\big \\rangle$ is the mean squared distance, t is time, $D_t$ is the diffusion rate and C is a constant. If $\\Big \\langle r_{i}^{2} \\big \\rangle$ is plotted as a function of time, the gradient of the curve obtained is equal to 6 times the self-diffusion coefficient of particle i. \n",
    "The state of the matter effects the shape of the MSD plot, solids, where little to no diffusion is occuring, has a flat MSD profile. In a liquid however, the particles diffusion randomly and the gradient of the curve is proportional to the diffusion coefficient. \n",
    "\n",
    "## What is the mean squared displacement\n",
    "\n",
    "Going back to the example of the dye in water, lets assume for the sake of simplicity that we are in one dimension. Each step can either be forwards or backwards and we cannot predict which. From a given starting position, what distance is our dye molecule likely to travel after 1000 steps? This can be determined simply by adding together the steps, taking into account the fact that steps backwards subtract from the total, while steps forward add to the total. Since both forward and backward steps are equally probable, we come to the surprising conclusion that the probable distance travelled sums up to zero.\n",
    "\n",
    "By adding the square of the distance we will always be adding positive numbers to our total which now increases linearly with time. Based upon equation 1 it should now be clear that a plot of $\\Big \\langle r_{i}^{2} \\big \\rangle$ vs time with produce a line, the gradient of which is equal to 6D. Giving us direct access to the diffusion coefficient of the system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polypy import read as rd\n",
    "from polypy import msd as msd\n",
    "from polypy import utils as ut\n",
    "from polypy import write as wr\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import corner\n",
    "from sklearn.utils import resample\n",
    "from uravu.relationship import Relationship\n",
    "from uravu import plotting, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "import numpy as np\n",
    "\n",
    "def straightline(x, m, c):\n",
    "    \"\"\" \n",
    "    Calculate y for a straight line\n",
    "    \n",
    "    Args:\n",
    "        x (list): the abscissa values at which the data/model is defined\n",
    "        m (float): the gradient of the straight line\n",
    "        c (float): the intercept of the straight line\n",
    "    \"\"\"\n",
    "    return m * x + c\n",
    "\n",
    "def loglikelihood(theta, y, dy, x):\n",
    "    \"\"\"\n",
    "    The natural logarithm of the joint likelihood, equation from \n",
    "    DOI: 10.1107/S1600576718017296\n",
    "    \n",
    "    Args:\n",
    "        theta (tuple): a sample containing individual parameter values\n",
    "        y (list): the set of data/observations\n",
    "        dy (list): the standard deviation of the data points\n",
    "        x (list): the abscissa values at which the data/model is defined\n",
    "    \"\"\"\n",
    "    \n",
    "    m, c = theta\n",
    "    \n",
    "    md = straightline(x, m, c)\n",
    "    \n",
    "    return -0.5*np.sum(((md - y)/dy)**2 + np.log(2 * np.pi * dy ** 2))\n",
    "\n",
    "def mcmc_sample(y, x, dy, m, c, n_samples=500, n_burn=500):\n",
    "    \"\"\"\n",
    "    The MCMC sampler using emcee\n",
    "\n",
    "    Args:\n",
    "        y (list): the set of data/observations\n",
    "        dy (float): the standard deviation of the data points\n",
    "        x (list): the abscissa values at which the data/model is defined\n",
    "        m (float): an initial guess of the gradient\n",
    "        c (float): an initial guess of the intercept\n",
    "        n_samples (int): number of samples\n",
    "        n_burn (int): number of burn in samples (will be ignored)\n",
    "    \"\"\"\n",
    "    walkers = 100  \n",
    "\n",
    "    m_min = m - 10. * m\n",
    "    m_max = m + 10. * m\n",
    "\n",
    "    mini = np.random.uniform(m_min, m_max, walkers) \n",
    "\n",
    "    c_min = c - 10. * c  \n",
    "    c_max = c + 10. * c  \n",
    "\n",
    "    cini = np.random.uniform(c_min, c_max, walkers)\n",
    "\n",
    "    inisamples = np.array([mini, cini]).T \n",
    "\n",
    "    ndims = inisamples.shape[1] \n",
    "\n",
    "    argslist = (y, dy, x)\n",
    "\n",
    "    sampler = emcee.EnsembleSampler(walkers, ndims, loglikelihood, args=argslist)\n",
    "\n",
    "    sampler.run_mcmc(inisamples, n_samples + n_burn);\n",
    "\n",
    "    postsamples = sampler.chain[:, n_burn:, :].reshape((-1, ndims))\n",
    "\n",
    "    return postsamples, sampler, ndims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will use a short (50,000 steps), pre-prepared trajectory of bulk $CaF_2$. In reality we probably want a considerably longer simulation (~10,000,000 steps). Such simulations generate huge files (5GB) and the analysis would take too long for this tutorial. \n",
    "\n",
    "The first step is to read the history file to generate the data. The function read_history expects two things, the filename of the history file and a list of atoms to read. It will return a dictionary containing the atom labels, trajectories, lattice vectors, timesteps and number of atoms.\n",
    "\n",
    "```\n",
    "data = {'label': Atom Names,\n",
    "        'trajectories': Atomic trajectories,\n",
    "        'lv': Lattice vectors,\n",
    "        'timesteps': Number of timesteps,\n",
    "        'natoms': Number of Atoms}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "#data = rd.read_history(\"../../../../HISTORY\", [\"PA\"])\n",
    "#print(data['frac_trajectories'])\n",
    "#print(data['trajectories'])\n",
    "\n",
    "\n",
    "data = rd.read_history(\"../example_data/HISTORY\", [\"F\"])\n",
    "\n",
    "print(data['timesteps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been read into the code the MSD calculation can be performed. The msd function requires the data and the time between records which in this case is 0.25ps. The msd function will then return a dictionary containing the time, 3D MSD and the directional components. \n",
    "\n",
    "```\n",
    "data = {'msd': 3D MSD,\n",
    "        'xmsd': MSD in the X direction,\n",
    "        'ymsd': MSD in the Y direction,\n",
    "        'zmsd': MSD in the Z direction,\n",
    "        'time': Time}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "msd_data = msd.msd(data, timestep=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-9ae22869553b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-9ae22869553b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    =\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data can then be plotted using the plot function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.msd_plot(msd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(msd_data['sd_time'], msd_data['squared_displacements'], s=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(msd_data['squared_displacements'][-data['natoms']:-1], bins=100)\n",
    "plt.axvline(np.mean(msd_data['squared_displacements'][-data['natoms']:-1]), ls=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = msd_data['squared_displacements']\n",
    "dataset = np.split(dataset, data['timesteps']-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confidence_intervals = []\n",
    "means = []\n",
    "all_data = np.zeros((data['timesteps']-1, 1000))\n",
    "all_means = []\n",
    "all_times = []\n",
    "errors = []\n",
    "for i in range(data['timesteps']-1):\n",
    "    sampled_means = [np.mean(resample(dataset[i], replace=True, n_samples=100)) for j in range(1000)]\n",
    "    means.append(np.mean(sampled_means))\n",
    "    all_data[i,:] = np.array(sampled_means)\n",
    "    all_means.append(sampled_means)\n",
    "    errors.append(np.std(sampled_means))\n",
    "    confidence_intervals.append([np.percentile(sampled_means, 2.5), np.percentile(sampled_means, 97.5)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = np.asarray(all_means)\n",
    "plt.plot(msd_data['sd_time'], all_means.flatten(), '.', alpha=0.005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "ci_arr = np.array(confidence_intervals).T\n",
    "y_error = np.array([msd_data['msd'] - ci_arr[0], ci_arr[1] - msd_data['msd']])\n",
    "plt.errorbar(msd_data['time'], msd_data['msd'], yerr=y_error, alpha=0.2)\n",
    "res = linregress(msd_data['time'], msd_data['msd'])\n",
    "ps, sampler, ndims = mcmc_sample(msd_data['msd'], msd_data['time'], y_error, res.slope, res.intercept, 2000, 2000)\n",
    "a = np.random.choice(ps.shape[0], size=100)\n",
    "for k in ps[a]:\n",
    "    plt.plot(msd_data['time'], straightline(msd_data['time'], k[0], k[1]), 'tab:green', alpha=0.05)\n",
    "\n",
    "plt.title(i)\n",
    "plt.show()\n",
    "fig = corner.corner(ps, labels=[r\"$m$\", r\"$c$\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain(discard=100)\n",
    "labels = [\"m\", \"c\"]\n",
    "for i in range(ndims):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mcmc = np.percentile(samples[:, i], [16, 50, 84])\n",
    "print(np.mean(np.mean(samples, axis=0), axis=0), np.std(np.std(samples, axis=0), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data the diffusion coefficient can then be calculated from the slopes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diff = ut.linear_regression(msd_data['time'], msd_data['msd'])[0]\n",
    "Diffusion_Coefficient = ut.three_d_diffusion_coefficient(Diff)\n",
    "\n",
    "XYDiff = ut.linear_regression(msd_data['time'], msd_data['xymsd'])[0]\n",
    "XYDiffusion_Coefficient = ut.two_d_diffusion_coefficient(XYDiff)#\n",
    "\n",
    "XZDiff = ut.linear_regression(msd_data['time'], msd_data['xzmsd'])[0]\n",
    "XZDiffusion_Coefficient = ut.two_d_diffusion_coefficient(XZDiff)\n",
    "\n",
    "YZDiff = ut.linear_regression(msd_data['time'], msd_data['yzmsd'])[0]\n",
    "YZDiffusion_Coefficient = ut.two_d_diffusion_coefficient(YZDiff)\n",
    "\n",
    "XDiff = ut.linear_regression(msd_data['time'], msd_data['xmsd'])[0]\n",
    "XDiffusion_Coefficient = ut.one_d_diffusion_coefficient(XDiff)#\n",
    "\n",
    "YDiff = ut.linear_regression(msd_data['time'], msd_data['ymsd'])[0]\n",
    "YDiffusion_Coefficient = ut.one_d_diffusion_coefficient(YDiff)\n",
    "\n",
    "ZDiff = ut.linear_regression(msd_data['time'], msd_data['zmsd'])[0]\n",
    "ZDiffusion_Coefficient = ut.one_d_diffusion_coefficient(ZDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Three Dimensional Diffusion Coefficient\", Diffusion_Coefficient)\n",
    "print(\"Two Dimensional Diffusion Coefficient in XY\", XYDiffusion_Coefficient)\n",
    "print(\"Two Dimensional Diffusion Coefficient in XZ\", XZDiffusion_Coefficient)\n",
    "print(\"Two Dimensional Diffusion Coefficient in YZ\", YZDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in X\", XDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in Y\", YDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in Z\", ZDiffusion_Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = np.mean(ut.system_volume(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYZCond = ut.conductivity(data['natoms'], volume, Diffusion_Coefficient, 1500)\n",
    "print(\"Three Dimensional Conductivity\", XYZCond)\n",
    "XYCond = ut.conductivity(data['natoms'], volume, XYDiffusion_Coefficient, 1500)\n",
    "print(\"Two Dimensional Conductivity in XY\", XYCond)\n",
    "XZCond = ut.conductivity(data['natoms'], volume, XZDiffusion_Coefficient, 1500)\n",
    "print(\"Two Dimensional Conductivity in XZ\", XZCond)\n",
    "YZCond = ut.conductivity(data['natoms'], volume, YZDiffusion_Coefficient, 1500)\n",
    "print(\"Two Dimensional Conductivity in YZ\", YZCond)\n",
    "XCond = ut.conductivity(data['natoms'], volume, XDiffusion_Coefficient, 1500)\n",
    "print(\"One Dimensional Conductivity in X\", XCond)\n",
    "YCond = ut.conductivity(data['natoms'], volume, YDiffusion_Coefficient, 1500)\n",
    "print(\"One Dimensional Conductivity in Y\", YCond)\n",
    "ZCond = ut.conductivity(data['natoms'], volume, ZDiffusion_Coefficient, 1500)\n",
    "print(\"One Dimensional Conductivity in Z\", ZCond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Smoothing the MSD\n",
    "\n",
    "This example has used one sweep of the trajectory, meaning that the MSD has been calculated from one value of $r_{i}^{0}$. In order to increase your statistics and sharpen your  MSD plot it is often better to use multiple values of $r_{i}^{0}$. Basically, use multiple starting points. The smooth_msd function allows you to increase the number of runs with the runs parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smsd_data = msd.smooth_msd(data, 0.1, runs=5)\n",
    "\n",
    "np.savetxt(\"squared_displacements.csv\", np.array([smsd_data['sd_time'], smsd_data['squared_displacements']]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = np.genfromtxt(\"squared_displacements.csv\", delimiter=\",\")\n",
    "plt.scatter(tp[0], tp[1], alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data can then be plotted, and clearly the line is less noisey and thus the gradient is much more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.msd_plot(smsd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(smsd_data['sd_time'], smsd_data['squared_displacements'], s=10, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(smsd_data['squared_displacements'][-data['natoms']:-1], bins=100)\n",
    "plt.axvline(np.mean(smsd_data['squared_displacements'][-data['natoms']:-1]), ls=\"--\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = {'time': smsd_data['sd_time'], 'sd': smsd_data['squared_displacements']}\n",
    "dataset = pd.DataFrame(xy).sort_values(by='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_intervals = []\n",
    "means = []\n",
    "all_data = np.zeros((data['timesteps']-1, 1000))\n",
    "all_times = []\n",
    "all_means = []\n",
    "errors = []\n",
    "count = 0\n",
    "for time, sd in dataset.groupby('time'):\n",
    "    times = np.zeros(1000) + time\n",
    "    all_times.append(times.tolist())\n",
    "    sampled_means = [np.mean(resample(sd['sd'], replace=True, n_samples=100)) for j in range(1000)]\n",
    "    means.append(np.mean(sampled_means))\n",
    "    all_data[count,:] = np.array(sampled_means)\n",
    "    \n",
    "    all_means.append(sampled_means)\n",
    "    errors.append(np.std(sampled_means))\n",
    "    confidence_intervals.append([np.percentile(sampled_means, 2.5), np.percentile(sampled_means, 97.5)])\n",
    "    count = count + 1\n",
    "    \n",
    "\n",
    "all_means = np.asarray(all_means)\n",
    "all_times = np.asarray(all_times)\n",
    "\n",
    "plt.plot(all_times.flatten(), all_means.flatten(), '.', alpha=0.005)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "ci_arr = np.array(confidence_intervals).T\n",
    "y_error = np.array([smsd_data['msd'] - ci_arr[0], ci_arr[1] - smsd_data['msd']])\n",
    "plt.errorbar(smsd_data['time'], smsd_data['msd'], yerr=y_error, alpha=0.2)\n",
    "res = linregress(smsd_data['time'], smsd_data['msd'])\n",
    "ps, sampler, ndims = mcmc_sample(smsd_data['msd'], smsd_data['time'], y_error, res.slope, res.intercept, 2000, 2000)\n",
    "a = np.random.choice(ps.shape[0], size=100)\n",
    "for k in ps[a]:\n",
    "    plt.plot(smsd_data['time'], straightline(smsd_data['time'], k[0], k[1]), 'tab:green', alpha=0.05)\n",
    "\n",
    "plt.title(i)\n",
    "plt.show()\n",
    "fig = corner.corner(ps, labels=[r\"$m$\", r\"$c$\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(10, 7), sharex=True)\n",
    "samples = sampler.get_chain(discard=100)\n",
    "labels = [\"m\", \"c\"]\n",
    "for i in range(ndims):\n",
    "    ax = axes[i]\n",
    "    ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "    ax.set_xlim(0, len(samples))\n",
    "    ax.set_ylabel(labels[i])\n",
    "    ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "\n",
    "axes[-1].set_xlabel(\"step number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diff = ut.linear_regression(smsd_data['time'], smsd_data['msd'])[0]\n",
    "Diffusion_Coefficient = ut.three_d_diffusion_coefficient(Diff)\n",
    "\n",
    "XDiff = ut.linear_regression(smsd_data['time'], smsd_data['xmsd'])[0]\n",
    "XDiffusion_Coefficient = ut.three_d_diffusion_coefficient(XDiff)\n",
    "\n",
    "YDiff = ut.linear_regression(smsd_data['time'], smsd_data['ymsd'])[0]\n",
    "YDiffusion_Coefficient = ut.three_d_diffusion_coefficient(YDiff)\n",
    "\n",
    "ZDiff = ut.linear_regression(smsd_data['time'], smsd_data['zmsd'])[0]\n",
    "ZDiffusion_Coefficient = ut.three_d_diffusion_coefficient(ZDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Three Dimensional Diffusion Coefficient\", Diffusion_Coefficient, \"\")\n",
    "print(\"One Dimensional Diffusion Coefficient in X\", XDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in Y\", YDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in Z\", ZDiffusion_Coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrhenius\n",
    "\n",
    "\n",
    "It is then possible to take diffusion coefficients, calculated over a large temperature range and, using the Arrhenius equation calculate the activation energy for diffusion. Common sense and chemical intuition suggest that the higher the temperature, the faster a given chemical reaction will proceed. Quantitatively this relationship between the rate a reaction proceeds and its temperature is determined by the Arrhenius Equation. At higher temperatures, the probability that two molecules will collide is higher. This higher collision rate results in a higher kinetic energy, which has an effect on the activation energy of the reaction. The activation energy is the amount of energy required to ensure that a reaction happens.  \n",
    "  \n",
    "\\begin{align}\n",
    "k = A * e^{(-Ea / RT)}\n",
    "\\end{align}\n",
    "  \n",
    "where k is the rate coefficient, A is a constant, Ea is the activation energy, R is the universal gas constant, and T is the temperature (in kelvin).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ionic Conductivity\n",
    "\n",
    "Usefully, as we have the diffusion coefficient, the number of particles (charge carriers) and the ability to calculate the volume, we can convert this data into the ionic conductivity and then the resistance. \n",
    "\n",
    "\\begin{align}\n",
    "\\sigma & = \\frac{D C_F e^2}{k_B T} \n",
    "\\end{align}\n",
    "\n",
    "where $\\sigma$ is the ionic conductivity, D is the diffusion coefficient, $C_F$ is the concentration of charge carriers, which in this case if F ions, $e^2$ is the charge of the diffusing species, $k_B$ is the Boltzmann constant and T is the temperature. \n",
    "\n",
    "The resitance can then be calculated according to \n",
    "\n",
    "\\begin{align}\n",
    "\\Omega & = \\frac{1}{\\sigma} \n",
    "\\end{align}\n",
    "\n",
    "So the first step is to calculate the volume, the system voume module will do this from the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = np.dot(data['lv'][-1][0,:], np.cross(data['lv'][-1][1,:], data['lv'][-1][2,:] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of charge carriers is just the total number of atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Number_of_Charge_Carriers = traj_obj.get_natoms(\"F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the conductivity can be calculated by the conductivity module, note that the temperature of this simulation was 1500 K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ionic_Conductivity = ut.conductivity(Number_of_Charge_Carriers, volume, Diffusion_Coefficient, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ionic Conductivity :\", Ionic_Conductivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Resistivity :\", (1 / Ionic_Conductivity)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Length\n",
    "\n",
    "It is important to consider the lenght of your simulation (Number of steps). The above examples use a short trajectory but it is at a sufficient temperature that there are enough diffusion events to get a good MSD plot. The following example is of a very short simulation, you will hopefully note that the MSD plot is clearly not converged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_short = rdpl.read_trajectory(\"../example_data/HISTORY_short\")\n",
    "short_traj = trajectory.PolyTrajectory(data_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_data = msd.msd(data_short, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.msd_plot(msd_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the diffusion coefficient is wrong. But without viewing the plot it is hard to tell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diff = ut.linear_regression(msd_data['time'], msd_data['msd'])\n",
    "Diffusion_Coefficient = ut.three_d_diffusion_coefficient(Diff)\n",
    "\n",
    "XDiff = ut.linear_regression(msd_data['time'], msd_data['xmsd'])\n",
    "XDiffusion_Coefficient = ut.three_d_diffusion_coefficient(XDiff)\n",
    "\n",
    "YDiff = ut.linear_regression(msd_data['time'], msd_data['ymsd'])\n",
    "YDiffusion_Coefficient = ut.three_d_diffusion_coefficient(YDiff)\n",
    "\n",
    "ZDiff = ut.linear_regression(msd_data['time'], msd_data['zmsd'])\n",
    "ZDiffusion_Coefficient = ut.three_d_diffusion_coefficient(ZDiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Three Dimensional Diffusion Coefficient\", Diffusion_Coefficient, \"\")\n",
    "print(\"One Dimensional Diffusion Coefficient in X\", XDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in Y\", YDiffusion_Coefficient)\n",
    "print(\"One Dimensional Diffusion Coefficient in Z\", ZDiffusion_Coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State of Matter\n",
    "\n",
    "It is possible to identify the phase of matter from the MSD plot.\n",
    "\n",
    "<center>\n",
    "    <br>\n",
    "    <img src=\"./figures/fig001.png\" width=\"400px\">\n",
    "    <i>Figure 1. The anticipated MSD form for each state of matter.</i>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "The Fluorine diffusion discussed already clearly shows that the fluorine sub lattice has melted and the diffusion is liquid like. Whereas, carrying out the same analysis on the Calcium sub lattice shows that while the fluorine sub lattice has melted, the Calcium sub lattice is still behaving like a solid. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional MSD Calculations\n",
    "\n",
    "Often in solid state chemistry simulations involve defects, both structural e.g. grain boundaries, dislocations and surface, and chemical e.g. point defects. It is important to try and isolate the contributions of these defects to the overall properties. Regarding diffusion, it could be imagined that a certain region within a structure will have different properties compared with the stoichiometric bulk, e.g. a grain boundary vs the grains, or the surface vs the bulk. `polypy` has the capability to isolate trajectories that pass within certain regions of a structure and thus calculate a diffusion coefficient for those regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "msd_data, transport_data = msd.plane_msd(data, 0.1, runs=1, ul=30, ll=-30, direction=\"x\")\n",
    "\n",
    "print(transport_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
